import pandas as pd

# Create the DataFrame with additional columns
data = {
    'name': ['nihad', 'nihad', 'nihad', 'alex', 'alex'],
    'ID': [234, 5, 8, 12, 13],
    'birthday': ['1990-01-01', '1990-01-01', '1990-01-01', '1985-05-05', '1985-05-05'],
    'email': ['nihad@example.com', 'nihad@example.com', 'nihad@example.com', 'alex@example.com', 'alex@example.com']
}
df = pd.DataFrame(data)

# Convert ID to string to concatenate
df['ID'] = df['ID'].astype(str)

# Define a custom aggregation function
def agg_func(x):
    if x.name == 'ID':
        return '|'.join(x)
    else:
        return x.iloc[0]

# Apply the aggregation function to each column
result = df.groupby('name').agg(agg_func).reset_index()

# View the result
print(result)




import pandas as pd

# Create the DataFrame with additional columns
data = {
    'name': ['nihad', 'nihad', 'nihad', 'alex', 'alex'],
    'ID': [234, 5, 8, 12, 13],
    'birthday': ['1990-01-01', '1990-01-01', '1990-01-01', '1985-05-05', '1985-05-05']
}
df = pd.DataFrame(data)

# Convert ID to string to concatenate
df['ID'] = df['ID'].astype(str)

# Define the aggregation function
agg_func = {
    'ID': '|'.join,
    'birthday': 'first'  # Modify this as needed for other columns
}

# Group by name and aggregate
result = df.groupby('name').agg(agg_func).reset_index()

# View the result
print(result)



import pandas as pd

# Create the DataFrame
data = {
    'name': ['nihad', 'nihad', 'nihad', 'alex', 'alex'],
    'ID': [234, 5, 8, 12, 13]
}
df = pd.DataFrame(data)

# Convert ID to string to concatenate
df['ID'] = df['ID'].astype(str)

# Group by name and concatenate IDs
result = df.groupby('name')['ID'].agg('|'.join).reset_index()

# Rename columns if needed
result.columns = ['name', 'concatenated_ID']

# View the result
print(result)




import pandas as pd

# Sample DataFrame
data = {
    'ID': [1, 2, 3, 4, 5],
    'cot': ['yes', 'no', 'yes', 'no', 'yes']
}

df = pd.DataFrame(data)

# Set ID to None (or NaN) where 'cot' is 'no'
df.loc[df['cot'] == 'no', 'ID'] = None

print(df)


Bonjour Karim,Le fichier KPI QAC contient les données et contrôles des domaines suivants : Crédits, Comptes, Transferts, Arrêtés, et Tiers. Il comprend un total de 165 données et 398 contrôles, incluant 7 nouvelles données et 9 nouveaux contrôles.À l'exception du domaine Produit, que nous n'avons pas encore ajouté au fichier GAC, où nous avons 5 données et 110 contrôles.Ainsi, le total est de 171 données et 508 contrôles. J'ai vérifié les colonnes et les lignes : le total est bien de 508 contrôles et 171 données, et non 509 et 172, car j'avais compté les en-têtes de l'Excel auparavant.Cordialement,
[Nihad Senhadji]




import pandas as pd

# Sample data including cases where name and family_name are identical
data = {
    'name': ['John', 'Jane', 'John', 'Alice', 'Bob', 'Bob'],
    'family_name': ['Doe', 'Smith', 'Doe', 'Johnson', 'Doe', 'Bob']
}

# Create DataFrame
df = pd.DataFrame(data)

# Function to keep only one value if name and family_name are the same
def combine_names(row):
    if row['name'] == row['family_name']:
        return row['name']
    else:
        return row['name'] + ' ' + row['family_name']

# Apply the function to combine name and family_name where they are equal
df['combined'] = df.apply(combine_names, axis=1)

# Drop the original name and family_name columns
df_final = df[['combined']]

# Display the final DataFrame
print(df_final)


import pandas as pd

# Sample DataFrame
data = {
    'name': ['John', 'Jane', 'Alice', 'John'],
    'family_name': ['Doe', 'Doe', 'Smith', 'Doe']
}

df = pd.DataFrame(data)

# Combine 'name' and 'family_name' into a single column
df['full_name'] = df['name'] + ' ' + df['family_name']

# Drop duplicates from the new column
df.drop_duplicates(subset=['full_name'], keep='first', inplace=True)

# Drop 'name' and 'family_name' columns if needed
df.drop(columns=['name', 'family_name'], inplace=True)

print(df



import pandas as pd

# Example DataFrame
data = {
    'name': ['John', 'Jane', 'Nihad', 'Michael', 'Nihad'],
    'family_name': ['Doe', 'Smith', 'Nihad', 'Johnson', 'Nihad']
}

df = pd.DataFrame(data)

# Create a new column 'full_name' to store concatenated values
df['full_name'] = ''

# Iterate through each row
for index, row in df.iterrows():
    if row['name'] == row['family_name']:
        df.at[index, 'full_name'] = row['name']
    else:
        df.at[index, 'full_name'] = row['name'] + ' ' + row['family_name']

# Drop the original 'name' and 'family_name' columns if needed
df = df.drop(columns=['name', 'family_name'])

print(df)


import pandas as pd

# Sample DataFrame
data = {
    'Name': ['John Doe', 'Jane Smith', 'Alice Wonderland', 'Bob Bob'],
    'rename': ['Doe', 'Smith', 'Wonderland', 'Bob']
}

df = pd.DataFrame(data)

# Initialize an empty list to store equal names
equal_names_list = []

# Function to concatenate names and identify equal cases
def concatenate_names_and_find_equal(row):
    nom = row['Name'].split()[1]  # Extract last name from 'Name' column
    prénom = row['rename']  # Get 'rename' value

    if nom == prénom:
        equal_names_list.append(row['Name'])  # Append 'Name' to the list if equal
        return row['Name'], row['Name']  # Return only the name if they are equal
    else:
        full_name = row['Name'] + " " + prénom
        return full_name, None

# Apply function row-wise
df[['Full Name', 'Equal Name and Family Name']] = df.apply(concatenate_names_and_find_equal, axis=1, result_type='expand')

# Print the DataFrame with results
print("DataFrame with concatenated names:")
print(df)

# Print the list of equal names
print("\nList of equal names:")
print(equal_names_list)



def concatenate_names_and_find_equal(nom, prénom):
    if nom == prénom:
        return nom, [nom]  # Return only the name if they are equal
    else:
        full_name = nom + " " + prénom
        if nom == prénom:
            return full_name, [nom]
        else:
            return full_name, []

# Example usage:
names = [
    ("Doe", "John"),
    ("Jane", "Jane"),
    ("Smith", "Smith"),
    ("Alice", "Wonderland")
]

for nom, prénom in names:
    full_name, equal_names = concatenate_names_and_find_equal(nom, prénom)
    print(f"Full Name: {full_name}")
    if equal_names:
        print(f"Equal Name and Family Name: {equal_names}")




import pandas as pd

# Sample DataFrame
data = {
    'Name': ['John Doe', 'Jane Smith', 'Alice Wonderland', 'Bob Bob'],
    'rename': ['Doe', 'Smith', 'Wonderland', 'Bob']
}

df = pd.DataFrame(data)

# Function to concatenate names and identify equal cases
def concatenate_names_and_find_equal(row):
    nom = row['Name'].split()[1]  # Extract last name from 'Name' column
    prénom = row['rename']  # Get 'rename' value

    if nom == prénom:
        return nom, nom  # Return only the name if they are equal
    else:
        full_name = row['Name'] + " " + prénom
        return full_name, None

# Apply function row-wise
df[['Full Name', 'Equal Name and Family Name']] = df.apply(concatenate_names_and_find_equal, axis=1, result_type='expand')

# Print the DataFrame with results
print(df)




def concatenate_names(nom, prénom):
    if nom == prénom:
        return nom  # Keep only one if they are the same
    else:
        return nom + " " + prénom  # Concatenate nom and prénom with a space in between

# Example usage:
nom = "Doe"
prénom = "John"
result = concatenate_names(nom, prénom)
print(result)  # Outputs: "Doe John"

nom = "Jane"
prénom = "Jane"
result = concatenate_names(nom, prénom)
print(result)  # Outputs: "Jane"


import pandas as pd

# Sample dataframe
data = {
    'Similarity score': [90, 96, 85, 100, 94, 97]
}
df = pd.DataFrame(data)

# Function to apply the conditions
def categorize_score(score):
    if 0 <= score <= 95:
        return "not found"
    elif score > 95:
        return ">95"

# Create the new column based on the conditions
df['Category'] = df['Similarity score'].apply(categorize_score)

print(df)





import streamlit as st
import pandas as pd
import io

# Streamlit app
st.title("Interdits de Chéquiers")

# Upload files
uploaded_interdicted_checks = st.file_uploader("Upload Interdicted Checks CSV", type="csv")
uploaded_client_database = st.file_uploader("Upload Client Database CSV", type="csv")

# Placeholder function for finding highest similarity
def find_highest_similarity(interdicted_checks, client_database, threshold=0.8):
    # Implement your similarity logic here
    # For the example, let's just return a sample DataFrame
    data = {'Interdicted': [1, 2, 3], 'Client': [4, 5, 6], 'Similarity': [0.9, 0.85, 0.95]}
    return pd.DataFrame(data)

# Function to save results to files
def save_results_to_files(df):
    # Save to CSV
    csv_buffer = io.StringIO()
    df.to_csv(csv_buffer, index=False)
    csv_data = csv_buffer.getvalue()
    
    # Save to Excel
    excel_buffer = io.BytesIO()
    with pd.ExcelWriter(excel_buffer, engine='xlsxwriter') as writer:
        df.to_excel(writer, index=False, sheet_name='Sheet1')
    excel_data = excel_buffer.getvalue()
    
    return excel_data, csv_data

# Load data and process on button click
if uploaded_interdicted_checks is not None and uploaded_client_database is not None:
    interdicted_checks = pd.read_csv(uploaded_interdicted_checks)
    client_database = pd.read_csv(uploaded_client_database)
    
    if st.button("Results"):
        result_df = find_highest_similarity(interdicted_checks, client_database, threshold=0.8)
        
        # Display results
        st.write("Similarity Results")
        st.dataframe(result_df)
        
        # Save results to files
        excel_data, csv_data = save_results_to_files(result_df)
        
        # Download buttons
        st.download_button(
            label="Download Results as CSV",
            data=csv_data,
            file_name='results.csv',
            mime='text/csv'
        )
        
        st.download_button(
            label="Download Results as Excel",
            data=excel_data,
            file_name='results.xlsx',
            mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
        )
else:
    st.write("Please upload both CSV files.")





Bonjour Hind,Racine m'a donné vos coordonnées car Salim est en congé. Nous avons une réunion avec SG samedi, donc serait-il possible de faire une réunion demain pour obtenir votre retour sur la solution IA proposée pour le problème des contrôles interdits ?Merci et bonne journée,
[Votre Nom]


Bonjour [Nom du destinataire],J'espère que vous allez bien.Comme vous le savez, Salim est actuellement en vacances. En son absence, notre équipe a développé un modèle IA pour résoudre le problème qu'il a démontré lors des récentes réunions SG.Nous aimerions qu'une personne, de préférence son remplaçant ou un autre individu qualifié, examine notre solution finale et nous donne son avis d'ici demain.Merci de nous faire savoir qui serait la meilleure personne pour cette tâche, ou s'il y a un moment convenable pour une réunion rapide de révision.Merci pour votre attention à cette question.Cordialement,


import streamlit as st
import pandas as pd

# Upload files
uploaded_interdicted_checks = st.file_uploader("Upload Interdicted Checks CSV", type="csv")
uploaded_client_database = st.file_uploader("Upload Client Database CSV", type="csv")

# Load data
if uploaded_interdicted_checks is not None and uploaded_client_database is not None:
    interdicted_checks = pd.read_csv(uploaded_interdicted_checks)
    client_database = pd.read_csv(uploaded_client_database)
    st.write("Interdicted Checks DataFrame:")
    st.write(interdicted_checks)
    st.write("Client Database DataFrame:")
    st.write(client_database)
else:
    st.write("Please upload both CSV files.")



import streamlit as st
import pandas as pd
import numpy as np
import re
import zipfile
from sentence_transformers import SentenceTransformer, util

# Function to preprocess names
def preprocess_name(name):
    name = name.lower()  # Convert to lowercase
    name = re.sub(r"[^a-z\s]", "", name)  # Remove special characters
    name = re.sub(r"\s+", "", name).strip()  # Remove extra whitespace
    for suffix in ['sarl', 'eurl', 'spa']:
        if name.endswith(suffix):
            name = suffix.strip() + name[:-len(suffix)].strip()
    return name

# Data cleaning function
def clean_data(interdicted_checks, client_database):
    # Cleaning interdicted_checks
    interdicted_checks['date_naissance'] = pd.to_datetime(interdicted_checks['date_naissance'], errors='coerce')
    interdicted_checks['nom'] = interdicted_checks['nom'].str.upper().fillna("")
    interdicted_checks['prenom'] = interdicted_checks['prenom'].str.upper().fillna("")
    interdicted_checks['Nom_abrege'] = interdicted_checks.apply(lambda row: f"{row['nom']} {row['prenom']}".strip(), axis=1)
    interdicted_checks['Nom_abrege'] = interdicted_checks['Nom_abrege'].str.replace(r'[^A-Z\s]', '', regex=True)
    interdicted_checks['Nom_abrege'] = interdicted_checks['Nom_abrege'].str.replace(r'\s+', ' ', regex=True).str.strip()
    
    interdicted_checks['Nom_abrege'] = interdicted_checks['Nom_abrege'].str.replace(r'\b(SARL|EURL|SPA|SAR)\b', '', regex=True).str.strip()
    
    # Cleaning client_database
    client_database['Code willaya de naissance'] = client_database['Code willaya de naissance'].fillna('8').astype('Int64')
    client_database['raison sociale clean'] = client_database['raison sociale clean'].apply(preprocess_name)
    client_database['raison sociale clean'] = client_database['raison sociale clean'].str.replace(r'[^a-z\s]', '', regex=True)
    client_database['raison sociale clean'] = client_database['raison sociale clean'].str.replace(r'\s+', ' ', regex=True).str.strip()
    client_database['raison sociale clean'] = client_database['raison sociale clean'].str.replace(r'\b(sarl|eurl|spa|sar)\b', '', regex=True).str.strip()

    return interdicted_checks, client_database

# Function to find highest similarity
def find_highest_similarity(df1, df2, threshold=0.8):
    model_path = "/mnt/Sentence_model_transformer"
    model = SentenceTransformer(model_path)
    
    names1 = df1['Nom_abrege'].tolist()
    names2 = df2['raison sociale clean'].tolist()
    
    embeddings1 = model.encode(names1, convert_to_tensor=True)
    embeddings2 = model.encode(names2, convert_to_tensor=True)
    
    similarity_matrix = util.pytorch_cos_sim(embeddings1, embeddings2).cpu().numpy()
    
    best_scores = {}
    best_pairs = {}
    
    for i in range(len(names1)):
        client_name = names1[i]
        for j in range(len(names2)):
            similarity_score = similarity_matrix[i][j]
            if similarity_score > threshold and similarity_score > best_scores.get(client_name, 0):
                best_scores[client_name] = similarity_score
                best_pairs[client_name] = (df2.iloc[j], similarity_score)
    
    similar_pairs = []
    for i in range(len(df1)):
        client_name = df1.iloc[i]['Nom_abrege']
        if client_name in best_pairs:
            client_match, similarity_score = best_pairs[client_name]
            similar_pairs.append({
                "Name interdicted_checks": client_name,
                "Date de naissance interdicted_checks": df1.iloc[i]['date_naissance'],
                "Lieu de naissance interdicted_checks": df1.iloc[i]['lieu de naissance'],
                "Name client database": client_match["raison sociale clean"],
                "Id": client_match["Id"],
                "Date de naissance client_database": client_match["date_naissance"],
                "Lieu de naissance client_database": client_match["lieu de naissance"],
                "Similarity Score": similarity_score
            })
    
    result_df = pd.DataFrame(similar_pairs)
    result_df["Date de naissance Match"] = result_df["Date de naissance interdicted_checks"] == result_df["Date de naissance client_database"]
    result_df["Lieu de naissance Match"] = result_df["Lieu de naissance interdicted_checks"] == result_df["Lieu de naissance client_database"]
    
    return result_df

# Function to save results to Excel and CSV
def save_results_to_files(result_df):
    below_threshold = result_df[result_df["Similarity Score"] < 0.95]
    above_threshold = result_df[result_df["Similarity Score"] > 0.95]
    dob_equal = result_df[result_df['Date de naissance client_database'] == result_df['Date de naissance interdicted_checks']]
    
    with pd.ExcelWriter('similarity_scores_VF_alldata.xlsx') as writer:
        below_threshold.to_excel(writer, sheet_name='Below_0.95', index=False)
        above_threshold.to_excel(writer, sheet_name='Above_0.95', index=False)
        dob_equal.to_excel(writer, sheet_name='DOB_Equal', index=False)
    
    result_df.to_csv('result_df_similarity_namevf_alldata.csv', index=False)
    return 'similarity_scores_VF_alldata.xlsx', 'result_df_similarity_namevf_alldata.csv'

# Streamlit app
st.title("Similarity Check Application")

# Upload files
uploaded_interdicted_checks = st.file_uploader("Upload Interdicted Checks CSV", type=["csv"])
uploaded_client_database = st.file_uploader("Upload Client Database CSV", type=["csv"])

if uploaded_interdicted_checks and uploaded_client_database:
    # Load data
    interdicted_checks = pd.read_csv(uploaded_interdicted_checks)
    client_database = pd.read_csv(uploaded_client_database)
    
    # Clean data
    interdicted_checks, client_database = clean_data(interdicted_checks, client_database)
    
    # Find similarities
    result_df = find_highest_similarity(interdicted_checks, client_database, threshold=0.8)
    
    # Display results
    st.write("Similarity Results")
    st.dataframe(result_df)
    
    # Save results to files
    excel_file, csv_file = save_results_to_files(result_df)
    
    # Option to download results
    with open(excel_file, "rb") as file:
        st.download_button(label="Download results as Excel", data=file, file_name=excel_file, mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
    
    with open(csv_file, "rb") as file:
        st.download_button(label="Download results as CSV", data=file, file_name=csv_file, mime="text/csv")
