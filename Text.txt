import pandas as pd
from sentence_transformers import SentenceTransformer, util

def find_highest_similarity(interdicted_checks, client_database, threshold=0.50):
    # Load sentence transformer model
    model_path = "/mnt/Sentence_model_transformer"
    model = SentenceTransformer(model_path)
    
    # Extract names from interdicted_checks and client_database
    names1 = interdicted_checks['Name'].tolist()
    names2 = client_database['name'].tolist()
    
    # Encode names1 and names2
    embeddings1 = model.encode(names1, convert_to_tensor=True)
    embeddings2 = model.encode(names2, convert_to_tensor=True)
    
    # Calculate cosine similarity matrix
    similarity_matrix = util.pytorch_cos_sim(embeddings1, embeddings2).cpu().numpy()
    
    # Initialize dictionaries to store highest similarity scores and corresponding interdicted clients
    best_scores = {}
    best_pairs = {}
    
    # Find the pairs with the highest similarity score for each client in interdicted_checks above the threshold
    for i in range(len(names1)):
        client_name = names1[i]
        for j in range(len(names2)):
            similarity_score = similarity_matrix[i][j]
            if similarity_score > threshold and similarity_score > best_scores.get(client_name, -1):
                best_scores[client_name] = similarity_score
                best_pairs[client_name] = (client_database.iloc[j], similarity_score)
    
    # Create list of pairs with highest similarity score for each client in interdicted_checks
    similar_pairs = []
    for i in range(len(interdicted_checks)):
        client_name = interdicted_checks.iloc[i]['Name']
        if client_name in best_pairs:
            client_match, similarity_score = best_pairs[client_name]
            similar_pairs.append({
                "Client from interdicted_checks": client_name,
                "DOB from interdicted_checks": interdicted_checks.iloc[i]['DOB'],
                "Address from interdicted_checks": interdicted_checks.iloc[i]['Address'],
                "Client from client_database": client_match['name'],
                "DOB from client_database": client_match['DOB'],
                "Address from client_database": client_match['Address'],
                "Similarity Score": similarity_score
            })
    
    # Create DataFrame from similar pairs
    result_df = pd.DataFrame(similar_pairs)
    
    # Add columns to check if DOBs and addresses are similar
    result_df["DOB Match"] = result_df.apply(lambda row: "Yes" if pd.isna(row["DOB from interdicted_checks"]) == pd.isna(row["DOB from client_database"]) and row["DOB from interdicted_checks"] == row["DOB from client_database"] else "No", axis=1)
    result_df["Address Match"] = result_df.apply(lambda row: "Yes" if pd.isna(row["Address from interdicted_checks"]) == pd.isna(row["Address from client_database"]) and row["Address from interdicted_checks"] == row["Address from client_database"] else "No", axis=1)
    
    return result_df

# Example data
interdicted_checks = pd.DataFrame({
    'Name': ['Alice Smith', 'Bob Johnson', 'Charlie Brown'],
    'DOB': ['1990-01-01', '1985-05-12', '1978-07-23'],
    'Address': ['123 Main St', '456 Oak St', '789 Pine St']
})

client_database = pd.DataFrame({
    'name': ['Alicia Smythe', 'Robert Johnson', 'Charles Browne', 'David Wilson'],
    'DOB': ['1990-01-01', '1985-05-12', '1978-07-23', '1992-11-02'],
    'Address': ['123 Main St', '456 Oak St', '789 Pine St', '101 Maple St']
})

result_df = find_highest_similarity(interdicted_checks, client_database, threshold=0.50)
print(result_df)





import pandas as pd
from sentence_transformers import SentenceTransformer, util

def find_highest_similarity(interdicted_checks, clients_data_base, threshold=0.50):
    # Load sentence transformer model
    model_path = "/mnt/Sentence_model_transformer"
    model = SentenceTransformer(model_path)
    
    # Extract names from interdicted_checks and clients_data_base
    names1 = interdicted_checks['Name'].tolist()
    names2 = clients_data_base['Name'].tolist()
    
    # Encode names1 and names2
    embeddings1 = model.encode(names1, convert_to_tensor=True)
    embeddings2 = model.encode(names2, convert_to_tensor=True)
    
    # Calculate cosine similarity matrix
    similarity_matrix = util.pytorch_cos_sim(embeddings1, embeddings2).cpu().numpy()
    
    # Initialize dictionaries to store highest similarity scores and corresponding interdicted clients
    best_scores = {}
    best_pairs = {}
    
    # Find the pairs with the highest similarity score for each client in interdicted_checks above the threshold
    for i in range(len(names1)):
        client_name = names1[i]
        for j in range(len(names2)):
            similarity_score = similarity_matrix[i][j]
            if similarity_score > threshold and similarity_score > best_scores.get(client_name, -1):
                best_scores[client_name] = similarity_score
                best_pairs[client_name] = (clients_data_base.iloc[j], similarity_score)
    
    # Create list of pairs with highest similarity score for each client in interdicted_checks
    similar_pairs = []
    for i in range(len(interdicted_checks)):
        client_name = interdicted_checks.iloc[i]['Name']
        if client_name in best_pairs:
            interdicted_client, similarity_score = best_pairs[client_name]
            similar_pairs.append({
                "Client from interdicted_checks": client_name,
                "DOB from interdicted_checks": interdicted_checks.iloc[i]['DOB'],
                "Address from interdicted_checks": interdicted_checks.iloc[i]['Address'],
                "Interdicted Client from clients_data_base": interdicted_client['Name'],
                "DOB from clients_data_base": interdicted_client['DOB'],
                "Address from clients_data_base": interdicted_client['Address'],
                "Similarity Score": similarity_score
            })
    
    # Create DataFrame from similar pairs
    result_df = pd.DataFrame(similar_pairs)
    
    # Add columns to check if DOBs and addresses are similar
    result_df["DOB Match"] = result_df.apply(lambda row: "Yes" if pd.isna(row["DOB from interdicted_checks"]) == pd.isna(row["DOB from clients_data_base"]) and row["DOB from interdicted_checks"] == row["DOB from clients_data_base"] else "No", axis=1)
    result_df["Address Match"] = result_df.apply(lambda row: "Yes" if pd.isna(row["Address from interdicted_checks"]) == pd.isna(row["Address from clients_data_base"]) and row["Address from interdicted_checks"] == row["Address from clients_data_base"] else "No", axis=1)
    
    return result_df

# Example data
interdicted_checks = pd.DataFrame({
    'Name': ['Alice Smith', 'Bob Johnson', 'Charlie Brown'],
    'DOB': ['1990-01-01', '1985-05-12', '1978-07-23'],
    'Address': ['123 Main St', '456 Oak St', '789 Pine St']
})

clients_data_base = pd.DataFrame({
    'Name': ['Alicia Smythe', 'Robert Johnson', 'Charles Browne', 'David Wilson'],
    'DOB': ['1990-01-01', '1985-05-12', '1978-07-23', '1992-11-02'],
    'Address': ['123 Main St', '456 Oak St', '789 Pine St', '101 Maple St']
})

result_df = find_highest_similarity(interdicted_checks, clients_data_base, threshold=0.50)
print(result_df)





import pandas as pd
from sentence_transformers import SentenceTransformer, util

def find_highest_similarity(df1, df2, threshold=0.50):
    # Load sentence transformer model
    model_path = "/mnt/Sentence_model_transformer"
    model = SentenceTransformer(model_path)
    
    # Extract names from df1 and df2
    names1 = df1['Name'].tolist()
    names2 = df2['Name'].tolist()
    
    # Encode names1 and names2
    embeddings1 = model.encode(names1, convert_to_tensor=True)
    embeddings2 = model.encode(names2, convert_to_tensor=True)
    
    # Calculate cosine similarity matrix
    similarity_matrix = util.pytorch_cos_sim(embeddings1, embeddings2).cpu().numpy()
    
    # Initialize dictionaries to store highest similarity scores and corresponding interdicted clients
    best_scores = {}
    best_pairs = {}
    
    # Find the pairs with the highest similarity score for each client in df1 above the threshold
    for i in range(len(names1)):
        client_name = names1[i]
        for j in range(len(names2)):
            similarity_score = similarity_matrix[i][j]
            if similarity_score > threshold and similarity_score > best_scores.get(client_name, -1):
                best_scores[client_name] = similarity_score
                best_pairs[client_name] = (df2.iloc[j], similarity_score)
    
    # Create list of pairs with highest similarity score for each client in df1
    similar_pairs = []
    for i in range(len(df1)):
        client_name = df1.iloc[i]['Name']
        if client_name in best_pairs:
            interdicted_client, similarity_score = best_pairs[client_name]
            similar_pairs.append({
                "Client from df1": client_name,
                "DOB from df1": df1.iloc[i]['DOB'],
                "Address from df1": df1.iloc[i]['Address'],
                "Interdicted Client from df2": interdicted_client['Name'],
                "DOB from df2": interdicted_client['DOB'],
                "Address from df2": interdicted_client['Address'],
                "Similarity Score": similarity_score
            })
    
    # Create DataFrame from similar pairs
    result_df = pd.DataFrame(similar_pairs)
    
    # Add columns to check if DOBs and addresses are similar
    result_df["DOB Match"] = result_df.apply(lambda row: "Yes" if row["DOB from df1"] == row["DOB from df2"] else "No", axis=1)
    result_df["Address Match"] = result_df.apply(lambda row: "Yes" if row["Address from df1"] == row["Address from df2"] else "No", axis=1)
    
    return result_df

# Example data
df1 = pd.DataFrame({
    'Name': ['Alice Smith', 'Bob Johnson', 'Charlie Brown'],
    'DOB': ['1990-01-01', '1985-05-12', '1978-07-23'],
    'Address': ['123 Main St', '456 Oak St', '789 Pine St']
})

df2 = pd.DataFrame({
    'Name': ['Alicia Smythe', 'Robert Johnson', 'Charles Browne', 'David Wilson'],
    'DOB': ['1990-01-01', '1985-05-12', '1978-07-23', '1992-11-02'],
    'Address': ['123 Main St', '456 Oak St', '789 Pine St', '101 Maple St']
})

result_df = find_highest_similarity(df1, df2, threshold=0.50)
print(result_df)





Bonjour,

Nous avons constaté l'absence de la donnée 'PM_TIERS' pour 1541 lignes ainsi que la donnée 'PM_COMPTE' pour 1899 lignes et 'PM_NOM' pour 1541 lignes dans l'extraction UAV_PHAYD101 arrêtée au 02-06-2024.

Merci de vérifier,

Cordialement,  
Nihad




from sentence_transformers import SentenceTransformer, util
import pandas as pd

# Example data (replace these with your actual data)
clients_database = {
    "id": [1, 2, 3],
    "name": ["client A", "client B", "client C"],
    "birthday": ["1990-01-01", "1985-05-15", "1992-11-30"],
    "birthday_location": ["City A", "City B", "City C"]
}
interdicted_checks = {
    "id": [101, 102, 103],
    "name": ["interdicted client X", "interdicted client Y", "interdicted client Z"],
    "birthday": ["1988-07-20", "1987-03-10", "1990-09-05"],
    "birthday_location": ["City X", "City Y", "City Z"]
}

# Extract names and IDs from the dictionaries
Liste1_ids = clients_database["id"]
Liste1_names = clients_database["name"]
Liste1_birthdays = clients_database["birthday"]
Liste1_birthday_locations = clients_database["birthday_location"]

Liste2_ids = interdicted_checks["id"]
Liste2_names = interdicted_checks["name"]
Liste2_birthdays = interdicted_checks["birthday"]
Liste2_birthday_locations = interdicted_checks["birthday_location"]

# Load sentence transformer model
model = SentenceTransformer('modelPath')  # Replace 'modelPath' with the actual model path

# Encode lists
embeddings1 = model.encode(Liste1_names, convert_to_tensor=True)
embeddings2 = model.encode(Liste2_names, convert_to_tensor=True)

# Calculate cosine similarity matrix using util.pytorch_cos_sim
similarity_matrix = util.pytorch_cos_sim(embeddings1, embeddings2).cpu().numpy()

# Initialize dictionaries to store highest similarity scores and corresponding interdicted clients
best_scores = {}
best_pairs = {}

# Find pairs with highest similarity score for each client in Liste1
for i in range(len(Liste1_ids)):
    client_id = Liste1_ids[i]
    client_name = Liste1_names[i]
    client_birthday = Liste1_birthdays[i]
    client_birthday_location = Liste1_birthday_locations[i]
    for j in range(len(Liste2_ids)):
        interdicted_id = Liste2_ids[j]
        interdicted_name = Liste2_names[j]
        interdicted_birthday = Liste2_birthdays[j]
        interdicted_birthday_location = Liste2_birthday_locations[j]
        similarity_score = similarity_matrix[i, j]
        if similarity_score > best_scores.get(client_id, -1):
            best_scores[client_id] = similarity_score
            best_pairs[client_id] = (interdicted_id, interdicted_name, interdicted_birthday, interdicted_birthday_location, similarity_score)

# Create list of pairs with highest similarity score for each client in Liste1
similar_pairs = [(client_id, client_name, client_birthday, client_birthday_location,
                  interdicted_id, interdicted_name, interdicted_birthday, interdicted_birthday_location,
                  similarity_score) for client_id, (interdicted_id, interdicted_name, interdicted_birthday, interdicted_birthday_location, similarity_score) in best_pairs.items()]

# Create a DataFrame to display the result
df = pd.DataFrame(similar_pairs, columns=["Client ID", "Client Database Name", "Client Birthday", "Client Birthday Location",
                                          "Interdicted Checks ID", "Interdicted Checks Name", "Interdicted Checks Birthday", "Interdicted Checks Birthday Location",
                                          "Similarity Score"])

# Display the DataFrame
print(df)





Bonjour Sara, je n'ai pas pu ouvrir le fichier que tu as envoyé. Peux-tu le vérifier et me le renvoyer ? Merci.



Bonjour,Nous avons constaté l'absence des dates d'expiration pour de nombreuses cartes numérotées 373352 dans le fichier select system. Merci de vérifier et mettre à jour ces informations dès que possible.Cordialement,




import pandas as pd
from sentence_transformers import SentenceTransformer, util
import numpy as np

def find_highest_similarity(df1, df2, threshold=0.50, model_name_or_path='paraphrase-MiniLM-L6-v2'):
    # Load sentence transformer model
    model = SentenceTransformer(model_name_or_path)
    
    # Extract names from df1 and df2
    names1 = df1['Name'].tolist()
    names2 = df2['Name'].tolist()
    
    # Encode names1 and names2
    embeddings1 = model.encode(names1, convert_to_tensor=True)
    embeddings2 = model.encode(names2, convert_to_tensor=True)
    
    # Calculate cosine similarity matrix
    similarity_matrix = util.pytorch_cos_sim(embeddings1, embeddings2).cpu().numpy()
    
    # Initialize dictionaries to store highest similarity scores and corresponding interdicted clients
    best_scores = {}
    best_pairs = {}

    # Find pairs with highest similarity score for each client in df1 above the threshold
    for i in range(len(names1)):
        client_name = names1[i]
        for j in range(len(names2)):
            similarity_score = similarity_matrix[i, j]
            if similarity_score >= threshold and similarity_score > best_scores.get(client_name, -1):
                best_scores[client_name] = similarity_score
                best_pairs[client_name] = (df2.iloc[j], similarity_score)
    
    # Create list of pairs with highest similarity score for each client in df1
    similar_pairs = []
    for i in range(len(df1)):
        client_name = df1.iloc[i]['Name']
        if client_name in best_pairs:
            interdicted_client = best_pairs[client_name][0]
            similarity_score = best_pairs[client_name][1]
            similar_pairs.append({
                "Client from df1": client_name,
                "DOB from df1": df1.iloc[i]['DOB'],
                "Address from df1": df1.iloc[i]['Address'],
                "Interdicted Client from df2": interdicted_client['Name'],
                "DOB from df2": interdicted_client['DOB'],
                "Address from df2": interdicted_client['Address'],
                "Similarity Score": similarity_score
            })
    
    # Create DataFrame from similar pairs
    result_df = pd.DataFrame(similar_pairs)
    
    # Add columns to check if DOBs and addresses are similar
    result_df["DOB Match"] = result_df.apply(lambda row: "Yes" if row["DOB from df1"] == row["DOB from df2"] else "No", axis=1)
    result_df["Address Match"] = result_df.apply(lambda row: "Yes" if row["Address from df1"] == row["Address from df2"] else "No", axis=1)
    
    return result_df

# Example DataFrame for df1 (replace with your actual data)
data1 = {
    "Name": ["nihad", "senhadji", "samia", "bnp tahraoui makhlouf", "pharma", "omar", "naciri", "ahlam"],
    "DOB": ["1990-01-01", "1985-05-12", "1992-07-19", "1988-11-23", "1983-03-03", "1990-04-14", "1995-09-27", "1982-12-30"],
    "Address": ["address1", "address2", "address3", "address4", "address5", "address6", "address7", "address8"]
}

df1 = pd.DataFrame(data1)

# Example DataFrame for df2 (replace with your actual data)
data2 = {
    "Name": ["nihrde", "spa pbn", "eurl tahraoui makhlou", "pharma sarl", "translates", "interdit1", "interdit2"],
    "DOB": ["1991-01-01", "1984-06-12", "1989-12-23", "1983-03-04", "1990-02-15", "1986-08-20", "1991-07-25"],
    "Address": ["address9", "address10", "address11", "address12", "address13", "address14", "address15"]
}

df2 = pd.DataFrame(data2)

# Set the threshold
threshold = 0.50

# Find pairs with highest similarity score for each client from df1
result_df = find_highest_similarity(df1, df2, threshold)

# Display the DataFrame
print(f"Pairs with similarity score above {threshold}:")
print(result_df)





import pandas as pd
from sentence_transformers import SentenceTransformer, util
import numpy as np

def df_to_list(df):
    """Convert a DataFrame to a list of tuples (Name, DOB, Address)."""
    return list(df.itertuples(index=False, name=None))

def find_highest_similarity(list1, list2, threshold=0.50, model_name_or_path='paraphrase-MiniLM-L6-v2'):
    # Load sentence transformer model
    model = SentenceTransformer(model_name_or_path)
    
    # Extract names from list1 and list2
    names1 = [item[0] for item in list1]
    names2 = [item[0] for item in list2]
    
    # Encode names1 and names2
    embeddings1 = model.encode(names1, convert_to_tensor=True)
    embeddings2 = model.encode(names2, convert_to_tensor=True)
    
    # Calculate cosine similarity matrix
    similarity_matrix = util.pytorch_cos_sim(embeddings1, embeddings2).cpu().numpy()
    
    # Initialize dictionaries to store highest similarity scores and corresponding interdicted clients
    best_scores = {}
    best_pairs = {}

    # Find pairs with highest similarity score for each client in list1 above the threshold
    for i in range(len(names1)):
        client_name = names1[i]
        for j in range(len(names2)):
            similarity_score = similarity_matrix[i, j]
            if similarity_score >= threshold and similarity_score > best_scores.get(client_name, -1):
                best_scores[client_name] = similarity_score
                best_pairs[client_name] = (list2[j], similarity_score)
    
    # Create list of pairs with highest similarity score for each client in list1
    similar_pairs = [(list1[i][0], list1[i][1], list1[i][2], best_pairs[list1[i][0]][0][0], best_pairs[list1[i][0]][0][1], best_pairs[list1[i][0]][0][2], best_pairs[list1[i][0]][1]) for i in range(len(list1)) if list1[i][0] in best_pairs]
    
    return similar_pairs

# Example DataFrame for Liste1 (replace with your actual data)
data1 = {
    "Name": ["nihad", "senhadji", "samia", "bnp tahraoui makhlouf", "pharma", "omar", "naciri", "ahlam"],
    "DOB": ["1990-01-01", "1985-05-12", "1992-07-19", "1988-11-23", "1983-03-03", "1990-04-14", "1995-09-27", "1982-12-30"],
    "Address": ["address1", "address2", "address3", "address4", "address5", "address6", "address7", "address8"]
}

df1 = pd.DataFrame(data1)

# Example list for Liste2 (replace with your actual data)
Liste2 = [
    ("nihrde", "1991-01-01", "address9"),
    ("spa pbn", "1984-06-12", "address10"),
    ("eurl tahraoui makhlou", "1989-12-23", "address11"),
    ("pharma sarl", "1983-03-04", "address12"),
    ("translates", "1990-02-15", "address13"),
    ("interdit1", "1986-08-20", "address14"),
    ("interdit2", "1991-07-25", "address15")
]

# Convert DataFrame to list
Liste1 = df_to_list(df1)

# Set the threshold
threshold = 0.50

# Find pairs with highest similarity score for each client from Liste1
similar_pairs = find_highest_similarity(Liste1, Liste2, threshold)

# Create a DataFrame to display the result
df = pd.DataFrame(similar_pairs, columns=["Client from Liste1", "DOB from Liste1", "Address from Liste1", 
                                          "Interdicted Client from Liste2", "DOB from Liste2", "Address from Liste2", 
                                          "Similarity Score"])

# Add columns to check if DOBs and addresses are similar
df["DOB Match"] = df.apply(lambda row: "Yes" if row["DOB from Liste1"] == row["DOB from Liste2"] else "No", axis=1)
df["Address Match"] = df.apply(lambda row: "Yes" if row["Address from Liste1"] == row["Address from Liste2"] else "No", axis=1)

# Display the DataFrame
print(f"Pairs with similarity score above {threshold}:")
print(df)





import pandas as pd
from sentence_transformers import SentenceTransformer, util
import numpy as np

def find_highest_similarity(list1, list2, threshold=0.50, model_name_or_path='paraphrase-MiniLM-L6-v2'):
    # Load sentence transformer model
    model = SentenceTransformer(model_name_or_path)
    
    # Extract names, date of birth, and address of birth from list1 and list2
    names1 = [item[0] for item in list1]
    dob1 = [item[1] for item in list1]
    address1 = [item[2] for item in list1]
    names2 = [item[0] for item in list2]
    dob2 = [item[1] for item in list2]
    address2 = [item[2] for item in list2]
    
    # Encode names1 and names2
    embeddings1 = model.encode(names1, convert_to_tensor=True)
    embeddings2 = model.encode(names2, convert_to_tensor=True)
    
    # Calculate cosine similarity matrix
    similarity_matrix = util.pytorch_cos_sim(embeddings1, embeddings2).cpu().numpy()
    
    # Initialize dictionaries to store highest similarity scores and corresponding interdicted clients
    best_scores = {}
    best_pairs = {}

    # Find pairs with highest similarity score for each client in names1 above the threshold
    for i in range(len(names1)):
        client_name = names1[i]
        client_dob = dob1[i]
        client_address = address1[i]
        for j in range(len(names2)):
            similarity_score = similarity_matrix[i, j]
            if similarity_score >= threshold and similarity_score > best_scores.get(client_name, -1):
                best_scores[client_name] = similarity_score
                best_pairs[client_name] = (names2[j], dob2[j], address2[j], similarity_score)
    
    # Create list of pairs with highest similarity score for each client in names1
    similar_pairs = [(client, client_dob, client_address, pair[0], pair[1], pair[2], pair[3]) for client, pair in best_pairs.items()]
    
    return similar_pairs

# Example lists (replace with your actual data)
Liste1 = [
    ("nihad", "1990-01-01", "address1"),
    ("senhadji", "1985-05-12", "address2"),
    ("samia", "1992-07-19", "address3"),
    ("bnp tahraoui makhlouf", "1988-11-23", "address4"),
    ("pharma", "1983-03-03", "address5"),
    ("omar", "1990-04-14", "address6"),
    ("naciri", "1995-09-27", "address7"),
    ("ahlam", "1982-12-30", "address8")
    # Add more clients
]

Liste2 = [
    ("nihrde", "1991-01-01", "address9"),
    ("spa pbn", "1984-06-12", "address10"),
    ("eurl tahraoui makhlou", "1989-12-23", "address11"),
    ("pharma sarl", "1983-03-04", "address12"),
    ("translates", "1990-02-15", "address13"),
    ("interdit1", "1986-08-20", "address14"),
    ("interdit2", "1991-07-25", "address15")
    # Replace with your 1,014 interdicted clients
]

# Set the threshold
threshold = 0.50

# Find pairs with highest similarity score for each client from Liste1
similar_pairs = find_highest_similarity(Liste1, Liste2, threshold)

# Create a DataFrame to display the result
df = pd.DataFrame(similar_pairs, columns=["Client from Liste1", "DOB from Liste1", "Address from Liste1", 
                                          "Interdicted Client from Liste2", "DOB from Liste2", "Address from Liste2", 
                                          "Similarity Score"])

# Add columns to check if DOBs and addresses are similar
df["DOB Match"] = df.apply(lambda row: "Yes" if row["DOB from Liste1"] == row["DOB from Liste2"] else "No", axis=1)
df["Address Match"] = df.apply(lambda row: "Yes" if row["Address from Liste1"] == row["Address from Liste2"] else "No", axis=1)

# Display the DataFrame
print(f"Pairs with similarity score above {threshold}:")
print(df)





def transform_date(date_str):
    if pd.isna(date_str):
        return date_str
    try:
        month, day, year = date_str.split('/')
        return f"{day}-{month}-{year}"
    except:
        return date_str

df['date_column'] = df['date_column'].apply(transform_date)


import pandas as pd

# Create a sample DataFrame with a 'date' column
data = {'date': ['12/12/2024', None, '01/01/2025']}
df = pd.DataFrame(data)

# Function to convert date format (handles None values)
def convert_date_format(date_str):
  if pd.isna(date_str):
    return None
  else:
    return pd.to_datetime(date_str).strftime('%d-%m-%Y')

# Apply the function to the 'date' column
df['date'] = df['date'].apply(convert_date_format)

# Print the DataFrame
print(df)




import pandas as pd

# Create a sample DataFrame
raw_data = pd.DataFrame({'Mycol': ['/12/2023', '10/05/2022', '/01/2021', '']})

# Convert the 'Mycol' column to datetime format
raw_data['Mycol'] = pd.to_datetime(raw_data['Mycol'], format='%d/%m/%Y')

# Replace empty strings with a default date (e.g., January 1, 2000)
raw_data['Mycol'] = raw_data['Mycol'].fillna(pd.to_datetime('2000-01-01'))

print(raw_data)








import pandas as pd
from sentence_transformers import SentenceTransformer, util
import numpy as np

def find_highest_similarity(list1, list2, model_name_or_path='paraphrase-MiniLM-L6-v2'):
    # Load sentence transformer model
    model = SentenceTransformer(model_name_or_path)
    
    # Encode list1 and list2
    embeddings1 = model.encode(list1, convert_to_tensor=True)
    embeddings2 = model.encode(list2, convert_to_tensor=True)
    
    # Calculate cosine similarity matrix
    similarity_matrix = util.pytorch_cos_sim(embeddings1, embeddings2).cpu().numpy()
    
    # Initialize dictionaries to store highest similarity scores and corresponding interdicted clients
    best_scores = {}
    best_pairs = {}

    # Find pairs with highest similarity score for each client in list1
    for i in range(len(list1)):
        client_name = list1[i]
        for j in range(len(list2)):
            similarity_score = similarity_matrix[i, j]
            if similarity_score > best_scores.get(client_name, -1):
                best_scores[client_name] = similarity_score
                best_pairs[client_name] = (list2[j], similarity_score)
    
    # Create list of pairs with highest similarity score for each client in list1
    similar_pairs = [(client, pair[0], pair[1]) for client, pair in best_pairs.items()]
    
    return similar_pairs

# Example lists (replace with your actual data)
Liste1 = ["nihad", "senhadji", "samia", "bnp tahraoui makhlouf", "pharma", "omar", "naciri", "ahlam", 
          "salma", "hafida", "fouzia", "samia", "sifo", "atika", "senhadji ninaf", "clientXYZ", "clientABC"]
Liste2 = ["nihrde", "spa pbn", "eurl tahraoui makhlou", "pharma sarl", "translates", "interdit1", "interdit2"]

# Find pairs with highest similarity score for each client from Liste1
similar_pairs = find_highest_similarity(Liste1, Liste2)

# Create a DataFrame to display the result
df = pd.DataFrame(similar_pairs, columns=["Client from Liste1", "Interdicted Client from Liste2", "Similarity Score"])

# Display the DataFrame
print("Pairs with highest similarity score for each client from Liste1:")
print(df)




from sentence_transformers import SentenceTransformer, util
import torch

def batch_process_similarity(list1, list2, batch_size=100, model_name_or_path='paraphrase-MiniLM-L6-v2'):
    # Load sentence transformer model
    model = SentenceTransformer(model_name_or_path)
    
    similarities = []

    # Process list1 in batches
    for i in range(0, len(list1), batch_size):
        batch1 = list1[i:i+batch_size]
        embeddings1 = model.encode(batch1, convert_to_tensor=True)
        
        for j in range(0, len(list2), batch_size):
            batch2 = list2[j:j+batch_size]
            embeddings2 = model.encode(batch2, convert_to_tensor=True)
            
            # Calculate cosine similarity matrix
            similarity_matrix = util.pytorch_cos_sim(embeddings1, embeddings2).cpu().numpy()
            
            # Loop through each pair and store similarity scores
            for row_idx in range(len(batch1)):
                for col_idx in range(len(batch2)):
                    similarities.append((batch1[row_idx], batch2[col_idx], similarity_matrix[row_idx, col_idx]))

    return similarities

# Example lists (replace with your actual data)
Liste1 = ["nihad", "senhadji", "samia", "bnp tahraoui makhlouf", "pharma", "omar", "naciri", "ahlam", 
          "salma", "hafida", "fouzia", "samia", "sifo", "atika", "senhadji ninaf", "clientXYZ", "clientABC", ...]  # Add more clients
Liste2 = ["nihrde", "spa pbn", "eurl tahraoui makhlou", "pharma sarl", "translates", "interdit1", "interdit2", ...]  # Replace with your 1,014 interdicted clients

# Calculate similarities in batches
similarities = batch_process_similarity(Liste1, Liste2)

# Print a sample of results (optional)
print("Sample Similarity Scores:")
for similarity in similarities[:10]:  # Print the first 10 similarities as an example
    print(f"{similarity[0]} <-> {similarity[1]} : {similarity[2]:.4f}")




from sentence_transformers import SentenceTransformer, util
from scipy.spatial.distance import cosine

def calculate_similarity(list1, list2, model_name_or_path='paraphrase-MiniLM-L6-v2'):
    # Load sentence transformer model
    model = SentenceTransformer(model_name_or_path)

    similarities = []
    for word1 in list1:
        for word2 in list2:
            # Compute embeddings
            embeddings = model.encode([word1, word2])
            # Compute cosine similarity
            similarity = 1 - cosine(embeddings[0], embeddings[1])
            similarities.append((word1, word2, similarity))
    return similarities

# Example lists
Liste1 = ["nihad", "senhadji", "samia"]
Liste2 = ["niahd", "aka", "lamia", "jamid", "monia", "fodial", "atmane", "omar"]

similarities = calculate_similarity(Liste1, Liste2)

# Print the results
print("Similarity Scores:")
for similarity in similarities:
    print(f"{similarity[0]} <-> {similarity[1]} : {similarity[2]}")




from fuzzywuzzy import fuzz

def find_matching_clients(clients_list, interdicted_cheques_list, threshold=70):
    matches = []
    for client in clients_list:
        for interdicted_name in interdicted_cheques_list:
            similarity_ratio = fuzz.ratio(client, interdicted_name)
            if similarity_ratio >= threshold:
                matches.append((client, interdicted_name, similarity_ratio))
    return matches

clients_list = ["nihad", "bnp tahraoui makhlouf", "pharma", "omar", "naciri", "ahlam", 
                "salma", "hafida", "fouzia", "samia", "sifo", "atika", "senhadji ninaf"]

interdicted_cheques_list = ["nihrde", "spa pbn ", "eurl tahraoui makhlou", "pharma sarl", "translates"]

matches = find_matching_clients(clients_list, interdicted_cheques_list)

if matches:
    print("Matches found:")
    for match in matches:
        print(f"Client: '{match[0]}' matches with Interdicted Cheque Name: '{match[1]}' (Similarity: {match[2]}%)")
else:
    print("No matches found.")




from collections import Counter

# Example list of names
names_list = ["nihad senhadji", "bessai Fatiha", "Fatiha"]

# Tokenize the names
tokens = []
for name in names_list:
    tokens.extend(name.lower().split())

# Count the occurrences of each token
token_counts = Counter(tokens)

# Print the token counts
for token, count in token_counts.items():
    print(f"{token}: {count}")



"Clients Interdits Chéquier"



import pandas as pd
from sentence_transformers import SentenceTransformer, util

# Sample data (replace with your actual data loading process)
clients_list = [
    "John Doe",
    "Alice Smith",
    "Michael Johnson",
    "Emily Brown",
    "Robert Lee",
    "Jennifer Davis",
    "David Wilson",
    "Sarah Martin",
    "Daniel Thompson",
    "Lisa Garcia"
]

# Sample monthly file data (replace with your actual data loading process)
monthly_file_df = pd.DataFrame({
    'Client_Name': [
        "John D.",
        "Alice S.",
        "Michael J.",
        "Emely B.",
        "Robert L.",
        "Jane Davis",
        "David Williams",
        "Daniel Thomson"
    ]
})

# Load the pre-trained Sentence Transformer model
model = SentenceTransformer('paraphrase-MiniLM-L6-v2')

# Encode client names
client_embeddings = model.encode(clients_list, convert_to_tensor=True)
monthly_embeddings = model.encode(monthly_file_df['Client_Name'].tolist(), convert_to_tensor=True)

# Calculate cosine similarity matrix
similarity_matrix = util.pytorch_cos_sim(monthly_embeddings, client_embeddings)

# Prepare to collect the most similar pairs
max_similarity_data = {'Monthly_Client_Name': [], 'Our_Client_Name': [], 'Similarity_Score': []}

# Set a threshold for similarity score
threshold = 0.85  # Adjust as per your requirement

# Find the most similar client name for each monthly file client
for i in range(len(monthly_file_df)):
    # Find index of the our client name with max similarity score
    max_sim_index = similarity_matrix[i].argmax().item()
    max_sim_score = similarity_matrix[i][max_sim_index].item()
    
    # Append the most similar pair if similarity score meets threshold
    if max_sim_score >= threshold:
        max_similarity_data['Monthly_Client_Name'].append(monthly_file_df['Client_Name'].iloc[i])
        max_similarity_data['Our_Client_Name'].append(clients_list[max_sim_index])
        max_similarity_data['Similarity_Score'].append(max_sim_score)

# Create DataFrame from collected data
max_similarity_df = pd.DataFrame(max_similarity_data)

# Print the resulting DataFrame
print(max_similarity_df)





import pandas as pd
from sentence_transformers import SentenceTransformer, util

# Sample data sizes
num_clients = 218000
num_interdicted_cheques = 1014

# Example lists (replace with your actual data loading process)
clients_list = [...]  # Load your 218000 client names
interdicted_cheques_list = [...]  # Load your 1014 interdicted cheques

# Load the pre-trained Sentence Transformer model
model = SentenceTransformer('paraphrase-MiniLM-L6-v2')

# Encode client names and interdicted cheques
client_embeddings = model.encode(clients_list, convert_to_tensor=True)
interdicted_embeddings = model.encode(interdicted_cheques_list, convert_to_tensor=True)

# Calculate cosine similarity matrix
similarity_matrix = util.pytorch_cos_sim(client_embeddings, interdicted_embeddings)

# Prepare to collect the most similar pairs
max_similarity_data = {'Client_Name': [], 'Interdicted_Name': [], 'Similarity_Score': []}

# Find the most similar interdicted cheque for each client
for i in range(num_clients):
    # Find index of the interdicted cheque with max similarity score
    max_sim_index = similarity_matrix[i].argmax().item()
    max_sim_score = similarity_matrix[i][max_sim_index].item()
    
    # Append the most similar pair to the data dictionary
    max_similarity_data['Client_Name'].append(clients_list[i])
    max_similarity_data['Interdicted_Name'].append(interdicted_cheques_list[max_sim_index])
    max_similarity_data['Similarity_Score'].append(max_sim_score)

    # Print progress
    if (i + 1) % 1000 == 0:
        print(f"Processed {i + 1} clients...")

# Create DataFrame from collected data
max_similarity_df = pd.DataFrame(max_similarity_data)

# Print the resulting DataFrame
print(max_similarity_df)




import pandas as pd
from sentence_transformers import SentenceTransformer, util

# Prepare the data
clients_list = ["nihad", "pharma", "naciri", "ahlam", "salma", "hafida", "fouzia", "samia", "sifo", "atika", "senhadji nihaf"]
interdicted_cheques_list = ["nihrde", "spa", "pharma sarl", "translates"]

# Load the model
model = SentenceTransformer('paraphrase-MiniLM-L6-v2')

# Encode the names
client_embeddings = model.encode(clients_list, convert_to_tensor=True)
interdicted_embeddings = model.encode(interdicted_cheques_list, convert_to_tensor=True)

# Calculate similarity matrix
similarity_matrix = util.pytorch_cos_sim(client_embeddings, interdicted_embeddings)

# Find the most similar pair
max_similarity_data = {'Client_Name': [], 'Interdicted_Name': [], 'Similarity_Score': []}

for i in range(len(clients_list)):
    # Find the index of the interdicted name with max similarity
    max_sim_index = similarity_matrix[i].argmax().item()
    max_sim_score = similarity_matrix[i][max_sim_index].item()
    
    # Add the pair to max_similarity_data if similarity score is above threshold
    if max_sim_score > 0.50:  # Adjust threshold as needed
        max_similarity_data['Client_Name'].append(clients_list[i])
        max_similarity_data['Interdicted_Name'].append(interdicted_cheques_list[max_sim_index])
        max_similarity_data['Similarity_Score'].append(max_sim_score)

# Create DataFrame from max similarity data
max_similarity_df = pd.DataFrame(max_similarity_data)
print(max_similarity_df)






import pandas as pd
from sentence_transformers import SentenceTransformer, util

# Prepare the data
clients_list = ["nihad", "pharma", "naciri", "ahlam", "salma", "hafida", "fouzia", "samia", "sifo", "atika", "senhadji nihaf"]
interdicted_cheques_list = ["nihrde", "spa", "pharma sarl", "translates"]

# Load the model
model = SentenceTransformer('paraphrase-MiniLM-L6-v2')

# Encode the names
client_embeddings = model.encode(clients_list, convert_to_tensor=True)
interdicted_embeddings = model.encode(interdicted_cheques_list, convert_to_tensor=True)

# Calculate similarity matrix
similarity_matrix = util.pytorch_cos_sim(client_embeddings, interdicted_embeddings)

# Define threshold and find matches
threshold = 0.50
matched_data = {'Client_Name': [], 'Interdicted_Name': [], 'Similarity_Score': []}

for i in range(len(clients_list)):
    for j in range(len(interdicted_cheques_list)):
        similarity_score = similarity_matrix[i][j].item()
        if similarity_score > threshold:
            matched_data['Client_Name'].append(clients_list[i])
            matched_data['Interdicted_Name'].append(interdicted_cheques_list[j])
            matched_data['Similarity_Score'].append(similarity_score)

# Create DataFrame from matches
matches_df = pd.DataFrame(matched_data)
print(matches_df)




from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

# Example lists (replace these with your actual data)
interdicted_clients = [
    "John Doe",
    "Jane Smith",
    "Alice Johnson",
    "Robert Brown",
    "Michael Clark"
]

client_database = [
    "Jon Doe",
    "Jane Smith",
    "Alice Johnson",
    "Robert Brown",
    "Michelle Clark"
]

# Initialize SentenceTransformer model
model = SentenceTransformer('distilbert-base-nli-stsb-mean-tokens')

# Encode names into embeddings
interdicted_embeddings = model.encode(interdicted_clients)
client_embeddings = model.encode(client_database)

# Function to find the best match using cosine similarity
def find_best_match(embedding, embeddings_list, names_list):
    similarities = cosine_similarity([embedding], embeddings_list)[0]
    best_match_index = np.argmax(similarities)
    best_match_name = names_list[best_match_index]
    best_similarity_score = similarities[best_match_index]
    return best_match_name, best_similarity_score

# Find matches and print results
print("Matches found:")
for i, interdicted_name in enumerate(interdicted_clients):
    best_match, similarity_score = find_best_match(interdicted_embeddings[i], client_embeddings, client_database)
    print(f"{interdicted_name} -> {best_match} (Similarity Score: {similarity_score:.4f})")




from sentence_transformers import SentenceTransformer, util
import pandas as pd

# Function to calculate embeddings
def calculate_embeddings(names_list, model):
    return model.encode(names_list, convert_to_tensor=True)

# Load the model (adjust modelPath as needed)
model = SentenceTransformer('modelPath')

# Sample Data (replace with actual data)
client_database = ['client_name1', 'client_name2', ...]  # 218,000 entries
interdicted_checks_clients = ['cheque_name1', 'cheque_name2', ...]  # 1,104 entries

# Calculate embeddings for both lists
client_database_embeddings = calculate_embeddings(client_database, model)
interdicted_checks_clients_embeddings = calculate_embeddings(interdicted_checks_clients, model)

# Calculate cosine similarity between embeddings (returns a tensor)
similarity_matrix_tensor = util.pytorch_cos_sim(client_database_embeddings, interdicted_checks_clients_embeddings)

# Initialize lists to store max similarity results
max_similarity_data = {'Client_Name': [], 'Cheque_Name': [], 'Max_Similarity_Score': []}

# Iterate over interdicted cheque list to find max similarity for each
for j in range(len(interdicted_checks_clients)):
    max_similarity_index = similarity_matrix_tensor[:, j].argmax().item()
    max_similarity_score = similarity_matrix_tensor[max_similarity_index, j].item()
    max_client_name = client_database[max_similarity_index]

    # Store the results
    max_similarity_data['Client_Name'].append(max_client_name)
    max_similarity_data['Cheque_Name'].append(interdicted_checks_clients[j])
    max_similarity_data['Max_Similarity_Score'].append(max_similarity_score)

# Create DataFrame from the collected data
max_similarity_df = pd.DataFrame(max_similarity_data)

print("Max Similarity DataFrame:\n", max_similarity_df)






from sentence_transformers import SentenceTransformer, util
import pandas as pd

# Function to calculate embeddings
def calculate_embeddings(list1, model):
    return model.encode(list1, convert_to_tensor=True)

# Load the model (adjust modelPath as needed)
model = SentenceTransformer('modelPath')

# Sample Data (replace with actual data)
clients = ['client_name1', 'client_name2', 'client_name3', 'client_name4']
interdicted_cheques = ['cheque_name1', 'cheque_name2', 'cheque_name3', 'cheque_name4']

# Calculate embeddings for both lists
clients_embeddings = calculate_embeddings(clients, model)
interdicted_cheques_embeddings = calculate_embeddings(interdicted_cheques, model)

# Calculate cosine similarity between embeddings
similarity_matrix = util.pytorch_cos_sim(clients_embeddings, interdicted_cheques_embeddings).numpy()

# Display the similarity matrix
print(similarity_matrix)

# Create DataFrame to store the max similarity results
max_similarity_data = {'Client_Name': [], 'Cheque_Name': [], 'Similarity_Score': []}

# Extract max similarity for each interdicted cheque name
threshold = 0.80

for i in range(len(interdicted_cheques)):
    for j in range(len(clients)):
        similarity_score = similarity_matrix[j][i]

        if similarity_score >= threshold:
            max_similarity_data['Client_Name'].append(clients[j])
            max_similarity_data['Cheque_Name'].append(interdicted_cheques[i])
            max_similarity_data['Similarity_Score'].append(similarity_score)

# Create DataFrame from the collected data
max_similarity_df = pd.DataFrame(max_similarity_data)

print(max_similarity_df)



from sentence_transformers import SentenceTransformer, util
import pandas as pd

# Function to calculate pairwise similarity
def calculate_similarity(list1, list2, model):
    embeddings1 = model.encode(list1, convert_to_tensor=True)
    embeddings2 = model.encode(list2, convert_to_tensor=True)
    similarity_matrix = util.pytorch_cos_sim(embeddings1, embeddings2)
    return similarity_matrix

# Load the model (adjust modelPath as needed)
model = SentenceTransformer('modelPath')

# Sample Data
clients = ['client_name1', 'client_name2', 'client_name3', 'client_name4']
interdicted_cheques = ['cheque_name1', 'cheque_name2', 'cheque_name3', 'cheque_name4']

# Calculate similarity matrix
similarity_matrix = calculate_similarity(clients, interdicted_cheques, model)

# Create DataFrame to store the max similarity results
max_similarity_data = {'Client_Name': [], 'Cheque_Name': [], 'Similarity_Score': []}

# Extract max similarity for each interdicted cheque name
threshold = 0.80

for i in range(len(interdicted_cheques)):
    for j in range(len(clients)):
        similarity_score = similarity_matrix[j][i].item()

        if similarity_score >= threshold:
            max_similarity_data['Client_Name'].append(clients[j])
            max_similarity_data['Cheque_Name'].append(interdicted_cheques[i])
            max_similarity_data['Similarity_Score'].append(similarity_score)

# Create DataFrame from the collected data
max_similarity_df = pd.DataFrame(max_similarity_data)

print(max_similarity_df)




import pandas as pd
import numpy as np
import torch
from sentence_transformers import SentenceTransformer, util

# Load the model
model = SentenceTransformer('all-MiniLM-L6-v2')

# Example data (replace these with your actual data)
client_database = ["Client Name 1", "Client Name 2", "Client Name 3"]  # Replace with your actual client data
interdicted_checks = ["Client Name A", "Client Name B", "Client Name 1"]  # Replace with your actual interdicted check data

# Get embeddings for client database and interdicted checks
client_database_embeddings = model.encode(client_database, convert_to_tensor=True)
interdicted_checks_embeddings = model.encode(interdicted_checks, convert_to_tensor=True)

# Calculate cosine similarity between client database and interdicted checks embeddings
similarity_matrix = util.pytorch_cos_sim(interdicted_checks_embeddings, client_database_embeddings).numpy()

# Create DataFrame to store the max similarity results
max_similarity_data = {
    "Interdicted_Name": [],
    "Matched_Client_Name": [],
    "Max_Similarity_Score": []
}

# Set the similarity threshold
threshold = 0.8
considered_pairs = set()  # Keep track of considered pairs to avoid duplicates

# Extract max similarity for each interdicted check name
for i in range(len(interdicted_checks)):
    similarity_row = similarity_matrix[i]
    max_similarity_index = np.argmax(similarity_row)
    max_similarity_score = similarity_row[max_similarity_index]
    
    if max_similarity_score >= threshold:
        current_pair = (interdicted_checks[i], client_database[max_similarity_index])
        reversed_pair = (client_database[max_similarity_index], interdicted_checks[i])
        
        if current_pair not in considered_pairs and reversed_pair not in considered_pairs:
            considered_pairs.add(current_pair)
            
            max_similarity_data["Interdicted_Name"].append(interdicted_checks[i])
            max_similarity_data["Matched_Client_Name"].append(client_database[max_similarity_index])
            max_similarity_data["Max_Similarity_Score"].append(max_similarity_score)

# Create DataFrame from the collected data
similarity_df = pd.DataFrame(max_similarity_data)

# Drop duplicate rows
similarity_df.drop_duplicates(inplace=True)

# Remove rows where 'Interdicted_Name' appears in 'Matched_Client_Name' to avoid redundancy
final_df = similarity_df[~similarity_df['Matched_Client_Name'].isin(similarity_df['Interdicted_Name'])]

print(final_df)




import pandas as pd

# Sample DataFrame with similar and different values
data = {
    'Column1': ['A', 'B', 'C', 'D'],
    'Column2': ['A', 'Y', 'C', 'X']
}

df = pd.DataFrame(data)

# Concatenating with condition to keep only one value if they are similar, with a space when concatenating
df['Concatenated'] = df.apply(
    lambda row: row['Column1'] if row['Column1'] == row['Column2'] else row['Column1'] + ' ' + row['Column2'], axis=1
)

print(df)




def normalize_names(row):
    name = row['name'] if pd.notna(row['name']) else ''
    family_name = row['family_name'] if pd.notna(row['family_name']) else ''

    # Strip whitespace
    name = name.strip()
    family_name = family_name.strip()

    # If both columns are empty, return a placeholder
    if name == '' and family_name == '':
        return 'unknown'
    
    # If both columns are non-empty and identical, keep one
    if name.lower() == family_name.lower():
        return name
    
    # If one of the columns is empty, use the non-empty column
    if name == '':
        return family_name
    if family_name == '':
        return name
    
    # Combine both fields if they are distinct
    return f"{name} {family_name}"



import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import re

# Load the datasets
interdicted_checks = pd.read_csv('interdicted_checks.csv')
client_database = pd.read_csv('client_database.csv')

# Data preprocessing function with handling for 'srl' and misaligned columns
def preprocess_name(name):
    name = name.lower()  # Convert to lowercase
    name = re.sub(r'[^a-z\s]', '', name)  # Remove special characters
    name = re.sub(r'\s+', ' ', name).strip()  # Remove extra whitespace
    if name.endswith(' srl'):
        name = 'srl ' + name[:-4].strip()  # Move 'srl' to the beginning
    return name

def normalize_names(row):
    # If both columns are non-empty and identical, keep one
    if pd.notna(row['name']) and pd.notna(row['family_name']):
        if row['name'].strip().lower() == row['family_name'].strip().lower():
            return row['name'].strip()
    # If family_name is empty, combine columns
    if pd.isna(row['family_name']) or row['family_name'].strip() == '':
        return row['name'].strip()
    # Combine both fields if they are distinct
    return f"{row['name'].strip()} {row['family_name'].strip()}"

# Apply normalization
interdicted_checks['combined_name'] = interdicted_checks.apply(normalize_names, axis=1)
client_database['combined_name'] = client_database.apply(normalize_names, axis=1)

# Apply preprocessing
interdicted_checks['clean_name'] = interdicted_checks['combined_name'].apply(preprocess_name)
client_database['clean_name'] = client_database['combined_name'].apply(preprocess_name)

# Vectorize names using TF-IDF
vectorizer = TfidfVectorizer().fit(pd.concat([interdicted_checks['clean_name'], client_database['clean_name']]))
interdicted_vectors = vectorizer.transform(interdicted_checks['clean_name'])
client_vectors = vectorizer.transform(client_database['clean_name'])

# Compute cosine similarity
similarity_matrix = cosine_similarity(interdicted_vectors, client_vectors)

# Identify the most similar names
threshold = 0.8  # Similarity threshold for considering a match
matches = []
for i, row in enumerate(similarity_matrix):
    max_sim = np.max(row)
    if max_sim >= threshold:
        client_index = np.argmax(row)
        matches.append((interdicted_checks['name'][i], client_database['name'][client_index], max_sim))

# Create a DataFrame of matches
matches_df = pd.DataFrame(matches, columns=['Interdicted Name', 'Client Name', 'Similarity'])
print(matches_df)

# Save the matches to a CSV file
matches_df.to_csv('matches.csv', index=False)






import pandas as pd
import numpy as np
import re
from sentence_transformers import SentenceTransformer, util

# Load the transformer model
model = SentenceTransformer('paraphrase-MiniLM-L6-v2')

# Load the datasets
interdicted_checks = pd.read_csv('interdicted_checks.csv')
client_database = pd.read_csv('client_database.csv')

# Data preprocessing function with handling for 'srl', 'eurl', and correction for 'sar'
def preprocess_name(name):
    name = name.lower()  # Convert to lowercase
    name = re.sub(r'[^a-z\s]', '', name)  # Remove special characters
    name = re.sub(r'\s+', ' ', name).strip()  # Remove extra whitespace
    # Correct 'sar' to 'sarl'
    if name.endswith(' sar'):
        name = name[:-3] + ' sarl'
    # Move known suffixes to the beginning
    for suffix in [' srl', ' eurl', ' sarl']:
        if name.endswith(suffix):
            name = suffix.strip() + ' ' + name[:-len(suffix)].strip()
    return name

def normalize_names(row):
    # If both columns are non-empty and identical, keep one
    if pd.notna(row['name']) and pd.notna(row['family_name']):
        if row['name'].strip().lower() == row['family_name'].strip().lower():
            return row['name'].strip()
    # If family_name is empty, combine columns
    if pd.isna(row['family_name']) or row['family_name'].strip() == '':
        return row['name'].strip()
    # Combine both fields if they are distinct
    return f"{row['name'].strip()} {row['family_name'].strip()}"

# Apply normalization
interdicted_checks['combined_name'] = interdicted_checks.apply(normalize_names, axis=1)
client_database['combined_name'] = client_database.apply(normalize_names, axis=1)

# Apply preprocessing
interdicted_checks['clean_name'] = interdicted_checks['combined_name'].apply(preprocess_name)
client_database['clean_name'] = client_database['combined_name'].apply(preprocess_name)

# Generate embeddings for names
interdicted_embeddings = model.encode(interdicted_checks['clean_name'].tolist(), convert_to_tensor=True)
client_embeddings = model.encode(client_database['clean_name'].tolist(), convert_to_tensor=True)

# Compute cosine similarity
cosine_scores = util.pytorch_cos_sim(interdicted_embeddings, client_embeddings)

# Identify the most similar names
threshold = 0.8  # Similarity threshold for considering a match
matches = []
for i in range(len(interdicted_checks)):
    for j in range(len(client_database)):
        if cosine_scores[i][j] >= threshold:
            matches.append((interdicted_checks['combined_name'][i], client_database['combined_name'][j], cosine_scores[i][j].item()))

# Create a DataFrame of matches
matches_df = pd.DataFrame(matches, columns=['Interdicted Name', 'Client Name', 'Similarity'])
print(matches_df)

# Save the matches to a CSV file
matches_df.to_csv('matches.csv', index=False)





import pandas as pd
import numpy as np
import re
from sentence_transformers import SentenceTransformer, util

# Load the transformer model
model = SentenceTransformer('paraphrase-MiniLM-L6-v2')

# Load the datasets
interdicted_checks = pd.read_csv('interdicted_checks.csv')
client_database = pd.read_csv('client_database.csv')

# Data preprocessing function with handling for 'srl', 'eurl', and other suffixes
def preprocess_name(name):
    name = name.lower()  # Convert to lowercase
    name = re.sub(r'[^a-z\s]', '', name)  # Remove special characters
    name = re.sub(r'\s+', ' ', name).strip()  # Remove extra whitespace
    # Move known suffixes to the beginning
    for suffix in [' srl', ' eurl']:
        if name.endswith(suffix):
            name = suffix.strip() + ' ' + name[:-len(suffix)].strip()
    return name

def normalize_names(row):
    # If both columns are non-empty and identical, keep one
    if pd.notna(row['name']) and pd.notna(row['family_name']):
        if row['name'].strip().lower() == row['family_name'].strip().lower():
            return row['name'].strip()
    # If family_name is empty, combine columns
    if pd.isna(row['family_name']) or row['family_name'].strip() == '':
        return row['name'].strip()
    # Combine both fields if they are distinct
    return f"{row['name'].strip()} {row['family_name'].strip()}"

# Apply normalization
interdicted_checks['combined_name'] = interdicted_checks.apply(normalize_names, axis=1)
client_database['combined_name'] = client_database.apply(normalize_names, axis=1)

# Apply preprocessing
interdicted_checks['clean_name'] = interdicted_checks['combined_name'].apply(preprocess_name)
client_database['clean_name'] = client_database['combined_name'].apply(preprocess_name)

# Generate embeddings for names
interdicted_embeddings = model.encode(interdicted_checks['clean_name'].tolist(), convert_to_tensor=True)
client_embeddings = model.encode(client_database['clean_name'].tolist(), convert_to_tensor=True)

# Compute cosine similarity
cosine_scores = util.pytorch_cos_sim(interdicted_embeddings, client_embeddings)

# Identify the most similar names
threshold = 0.8  # Similarity threshold for considering a match
matches = []
for i in range(len(interdicted_checks)):
    for j in range(len(client_database)):
        if cosine_scores[i][j] >= threshold:
            matches.append((interdicted_checks['combined_name'][i], client_database['combined_name'][j], cosine_scores[i][j].item()))

# Create a DataFrame of matches
matches_df = pd.DataFrame(matches, columns=['Interdicted Name', 'Client Name', 'Similarity'])
print(matches_df)

# Save the matches to a CSV file
matches_df.to_csv('matches.csv', index=False)
