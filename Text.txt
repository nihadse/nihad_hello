from sentence_transformers import SentenceTransformer, util
import pandas as pd

# Function to calculate embeddings
def calculate_embeddings(names_list, model):
    return model.encode(names_list, convert_to_tensor=True)

# Load the model (adjust modelPath as needed)
model = SentenceTransformer('modelPath')

# Sample Data (replace with actual data)
client_database = ['client_name1', 'client_name2', ...]  # 218,000 entries
interdicted_checks_clients = ['cheque_name1', 'cheque_name2', ...]  # 1,104 entries

# Calculate embeddings for both lists
client_database_embeddings = calculate_embeddings(client_database, model)
interdicted_checks_clients_embeddings = calculate_embeddings(interdicted_checks_clients, model)

# Calculate cosine similarity between embeddings (returns a tensor)
similarity_matrix_tensor = util.pytorch_cos_sim(client_database_embeddings, interdicted_checks_clients_embeddings)

# Initialize lists to store max similarity results
max_similarity_data = {'Client_Name': [], 'Cheque_Name': [], 'Max_Similarity_Score': []}

# Iterate over interdicted cheque list to find max similarity for each
for j in range(len(interdicted_checks_clients)):
    max_similarity_index = similarity_matrix_tensor[:, j].argmax().item()
    max_similarity_score = similarity_matrix_tensor[max_similarity_index, j].item()
    max_client_name = client_database[max_similarity_index]

    # Store the results
    max_similarity_data['Client_Name'].append(max_client_name)
    max_similarity_data['Cheque_Name'].append(interdicted_checks_clients[j])
    max_similarity_data['Max_Similarity_Score'].append(max_similarity_score)

# Create DataFrame from the collected data
max_similarity_df = pd.DataFrame(max_similarity_data)

print("Max Similarity DataFrame:\n", max_similarity_df)






from sentence_transformers import SentenceTransformer, util
import pandas as pd

# Function to calculate embeddings
def calculate_embeddings(list1, model):
    return model.encode(list1, convert_to_tensor=True)

# Load the model (adjust modelPath as needed)
model = SentenceTransformer('modelPath')

# Sample Data (replace with actual data)
clients = ['client_name1', 'client_name2', 'client_name3', 'client_name4']
interdicted_cheques = ['cheque_name1', 'cheque_name2', 'cheque_name3', 'cheque_name4']

# Calculate embeddings for both lists
clients_embeddings = calculate_embeddings(clients, model)
interdicted_cheques_embeddings = calculate_embeddings(interdicted_cheques, model)

# Calculate cosine similarity between embeddings
similarity_matrix = util.pytorch_cos_sim(clients_embeddings, interdicted_cheques_embeddings).numpy()

# Display the similarity matrix
print(similarity_matrix)

# Create DataFrame to store the max similarity results
max_similarity_data = {'Client_Name': [], 'Cheque_Name': [], 'Similarity_Score': []}

# Extract max similarity for each interdicted cheque name
threshold = 0.80

for i in range(len(interdicted_cheques)):
    for j in range(len(clients)):
        similarity_score = similarity_matrix[j][i]

        if similarity_score >= threshold:
            max_similarity_data['Client_Name'].append(clients[j])
            max_similarity_data['Cheque_Name'].append(interdicted_cheques[i])
            max_similarity_data['Similarity_Score'].append(similarity_score)

# Create DataFrame from the collected data
max_similarity_df = pd.DataFrame(max_similarity_data)

print(max_similarity_df)



from sentence_transformers import SentenceTransformer, util
import pandas as pd

# Function to calculate pairwise similarity
def calculate_similarity(list1, list2, model):
    embeddings1 = model.encode(list1, convert_to_tensor=True)
    embeddings2 = model.encode(list2, convert_to_tensor=True)
    similarity_matrix = util.pytorch_cos_sim(embeddings1, embeddings2)
    return similarity_matrix

# Load the model (adjust modelPath as needed)
model = SentenceTransformer('modelPath')

# Sample Data
clients = ['client_name1', 'client_name2', 'client_name3', 'client_name4']
interdicted_cheques = ['cheque_name1', 'cheque_name2', 'cheque_name3', 'cheque_name4']

# Calculate similarity matrix
similarity_matrix = calculate_similarity(clients, interdicted_cheques, model)

# Create DataFrame to store the max similarity results
max_similarity_data = {'Client_Name': [], 'Cheque_Name': [], 'Similarity_Score': []}

# Extract max similarity for each interdicted cheque name
threshold = 0.80

for i in range(len(interdicted_cheques)):
    for j in range(len(clients)):
        similarity_score = similarity_matrix[j][i].item()

        if similarity_score >= threshold:
            max_similarity_data['Client_Name'].append(clients[j])
            max_similarity_data['Cheque_Name'].append(interdicted_cheques[i])
            max_similarity_data['Similarity_Score'].append(similarity_score)

# Create DataFrame from the collected data
max_similarity_df = pd.DataFrame(max_similarity_data)

print(max_similarity_df)




import pandas as pd
import numpy as np
import torch
from sentence_transformers import SentenceTransformer, util

# Load the model
model = SentenceTransformer('all-MiniLM-L6-v2')

# Example data (replace these with your actual data)
client_database = ["Client Name 1", "Client Name 2", "Client Name 3"]  # Replace with your actual client data
interdicted_checks = ["Client Name A", "Client Name B", "Client Name 1"]  # Replace with your actual interdicted check data

# Get embeddings for client database and interdicted checks
client_database_embeddings = model.encode(client_database, convert_to_tensor=True)
interdicted_checks_embeddings = model.encode(interdicted_checks, convert_to_tensor=True)

# Calculate cosine similarity between client database and interdicted checks embeddings
similarity_matrix = util.pytorch_cos_sim(interdicted_checks_embeddings, client_database_embeddings).numpy()

# Create DataFrame to store the max similarity results
max_similarity_data = {
    "Interdicted_Name": [],
    "Matched_Client_Name": [],
    "Max_Similarity_Score": []
}

# Set the similarity threshold
threshold = 0.8
considered_pairs = set()  # Keep track of considered pairs to avoid duplicates

# Extract max similarity for each interdicted check name
for i in range(len(interdicted_checks)):
    similarity_row = similarity_matrix[i]
    max_similarity_index = np.argmax(similarity_row)
    max_similarity_score = similarity_row[max_similarity_index]
    
    if max_similarity_score >= threshold:
        current_pair = (interdicted_checks[i], client_database[max_similarity_index])
        reversed_pair = (client_database[max_similarity_index], interdicted_checks[i])
        
        if current_pair not in considered_pairs and reversed_pair not in considered_pairs:
            considered_pairs.add(current_pair)
            
            max_similarity_data["Interdicted_Name"].append(interdicted_checks[i])
            max_similarity_data["Matched_Client_Name"].append(client_database[max_similarity_index])
            max_similarity_data["Max_Similarity_Score"].append(max_similarity_score)

# Create DataFrame from the collected data
similarity_df = pd.DataFrame(max_similarity_data)

# Drop duplicate rows
similarity_df.drop_duplicates(inplace=True)

# Remove rows where 'Interdicted_Name' appears in 'Matched_Client_Name' to avoid redundancy
final_df = similarity_df[~similarity_df['Matched_Client_Name'].isin(similarity_df['Interdicted_Name'])]

print(final_df)




import pandas as pd

# Sample DataFrame with similar and different values
data = {
    'Column1': ['A', 'B', 'C', 'D'],
    'Column2': ['A', 'Y', 'C', 'X']
}

df = pd.DataFrame(data)

# Concatenating with condition to keep only one value if they are similar, with a space when concatenating
df['Concatenated'] = df.apply(
    lambda row: row['Column1'] if row['Column1'] == row['Column2'] else row['Column1'] + ' ' + row['Column2'], axis=1
)

print(df)




def normalize_names(row):
    name = row['name'] if pd.notna(row['name']) else ''
    family_name = row['family_name'] if pd.notna(row['family_name']) else ''

    # Strip whitespace
    name = name.strip()
    family_name = family_name.strip()

    # If both columns are empty, return a placeholder
    if name == '' and family_name == '':
        return 'unknown'
    
    # If both columns are non-empty and identical, keep one
    if name.lower() == family_name.lower():
        return name
    
    # If one of the columns is empty, use the non-empty column
    if name == '':
        return family_name
    if family_name == '':
        return name
    
    # Combine both fields if they are distinct
    return f"{name} {family_name}"



import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import re

# Load the datasets
interdicted_checks = pd.read_csv('interdicted_checks.csv')
client_database = pd.read_csv('client_database.csv')

# Data preprocessing function with handling for 'srl' and misaligned columns
def preprocess_name(name):
    name = name.lower()  # Convert to lowercase
    name = re.sub(r'[^a-z\s]', '', name)  # Remove special characters
    name = re.sub(r'\s+', ' ', name).strip()  # Remove extra whitespace
    if name.endswith(' srl'):
        name = 'srl ' + name[:-4].strip()  # Move 'srl' to the beginning
    return name

def normalize_names(row):
    # If both columns are non-empty and identical, keep one
    if pd.notna(row['name']) and pd.notna(row['family_name']):
        if row['name'].strip().lower() == row['family_name'].strip().lower():
            return row['name'].strip()
    # If family_name is empty, combine columns
    if pd.isna(row['family_name']) or row['family_name'].strip() == '':
        return row['name'].strip()
    # Combine both fields if they are distinct
    return f"{row['name'].strip()} {row['family_name'].strip()}"

# Apply normalization
interdicted_checks['combined_name'] = interdicted_checks.apply(normalize_names, axis=1)
client_database['combined_name'] = client_database.apply(normalize_names, axis=1)

# Apply preprocessing
interdicted_checks['clean_name'] = interdicted_checks['combined_name'].apply(preprocess_name)
client_database['clean_name'] = client_database['combined_name'].apply(preprocess_name)

# Vectorize names using TF-IDF
vectorizer = TfidfVectorizer().fit(pd.concat([interdicted_checks['clean_name'], client_database['clean_name']]))
interdicted_vectors = vectorizer.transform(interdicted_checks['clean_name'])
client_vectors = vectorizer.transform(client_database['clean_name'])

# Compute cosine similarity
similarity_matrix = cosine_similarity(interdicted_vectors, client_vectors)

# Identify the most similar names
threshold = 0.8  # Similarity threshold for considering a match
matches = []
for i, row in enumerate(similarity_matrix):
    max_sim = np.max(row)
    if max_sim >= threshold:
        client_index = np.argmax(row)
        matches.append((interdicted_checks['name'][i], client_database['name'][client_index], max_sim))

# Create a DataFrame of matches
matches_df = pd.DataFrame(matches, columns=['Interdicted Name', 'Client Name', 'Similarity'])
print(matches_df)

# Save the matches to a CSV file
matches_df.to_csv('matches.csv', index=False)






import pandas as pd
import numpy as np
import re
from sentence_transformers import SentenceTransformer, util

# Load the transformer model
model = SentenceTransformer('paraphrase-MiniLM-L6-v2')

# Load the datasets
interdicted_checks = pd.read_csv('interdicted_checks.csv')
client_database = pd.read_csv('client_database.csv')

# Data preprocessing function with handling for 'srl', 'eurl', and correction for 'sar'
def preprocess_name(name):
    name = name.lower()  # Convert to lowercase
    name = re.sub(r'[^a-z\s]', '', name)  # Remove special characters
    name = re.sub(r'\s+', ' ', name).strip()  # Remove extra whitespace
    # Correct 'sar' to 'sarl'
    if name.endswith(' sar'):
        name = name[:-3] + ' sarl'
    # Move known suffixes to the beginning
    for suffix in [' srl', ' eurl', ' sarl']:
        if name.endswith(suffix):
            name = suffix.strip() + ' ' + name[:-len(suffix)].strip()
    return name

def normalize_names(row):
    # If both columns are non-empty and identical, keep one
    if pd.notna(row['name']) and pd.notna(row['family_name']):
        if row['name'].strip().lower() == row['family_name'].strip().lower():
            return row['name'].strip()
    # If family_name is empty, combine columns
    if pd.isna(row['family_name']) or row['family_name'].strip() == '':
        return row['name'].strip()
    # Combine both fields if they are distinct
    return f"{row['name'].strip()} {row['family_name'].strip()}"

# Apply normalization
interdicted_checks['combined_name'] = interdicted_checks.apply(normalize_names, axis=1)
client_database['combined_name'] = client_database.apply(normalize_names, axis=1)

# Apply preprocessing
interdicted_checks['clean_name'] = interdicted_checks['combined_name'].apply(preprocess_name)
client_database['clean_name'] = client_database['combined_name'].apply(preprocess_name)

# Generate embeddings for names
interdicted_embeddings = model.encode(interdicted_checks['clean_name'].tolist(), convert_to_tensor=True)
client_embeddings = model.encode(client_database['clean_name'].tolist(), convert_to_tensor=True)

# Compute cosine similarity
cosine_scores = util.pytorch_cos_sim(interdicted_embeddings, client_embeddings)

# Identify the most similar names
threshold = 0.8  # Similarity threshold for considering a match
matches = []
for i in range(len(interdicted_checks)):
    for j in range(len(client_database)):
        if cosine_scores[i][j] >= threshold:
            matches.append((interdicted_checks['combined_name'][i], client_database['combined_name'][j], cosine_scores[i][j].item()))

# Create a DataFrame of matches
matches_df = pd.DataFrame(matches, columns=['Interdicted Name', 'Client Name', 'Similarity'])
print(matches_df)

# Save the matches to a CSV file
matches_df.to_csv('matches.csv', index=False)





import pandas as pd
import numpy as np
import re
from sentence_transformers import SentenceTransformer, util

# Load the transformer model
model = SentenceTransformer('paraphrase-MiniLM-L6-v2')

# Load the datasets
interdicted_checks = pd.read_csv('interdicted_checks.csv')
client_database = pd.read_csv('client_database.csv')

# Data preprocessing function with handling for 'srl', 'eurl', and other suffixes
def preprocess_name(name):
    name = name.lower()  # Convert to lowercase
    name = re.sub(r'[^a-z\s]', '', name)  # Remove special characters
    name = re.sub(r'\s+', ' ', name).strip()  # Remove extra whitespace
    # Move known suffixes to the beginning
    for suffix in [' srl', ' eurl']:
        if name.endswith(suffix):
            name = suffix.strip() + ' ' + name[:-len(suffix)].strip()
    return name

def normalize_names(row):
    # If both columns are non-empty and identical, keep one
    if pd.notna(row['name']) and pd.notna(row['family_name']):
        if row['name'].strip().lower() == row['family_name'].strip().lower():
            return row['name'].strip()
    # If family_name is empty, combine columns
    if pd.isna(row['family_name']) or row['family_name'].strip() == '':
        return row['name'].strip()
    # Combine both fields if they are distinct
    return f"{row['name'].strip()} {row['family_name'].strip()}"

# Apply normalization
interdicted_checks['combined_name'] = interdicted_checks.apply(normalize_names, axis=1)
client_database['combined_name'] = client_database.apply(normalize_names, axis=1)

# Apply preprocessing
interdicted_checks['clean_name'] = interdicted_checks['combined_name'].apply(preprocess_name)
client_database['clean_name'] = client_database['combined_name'].apply(preprocess_name)

# Generate embeddings for names
interdicted_embeddings = model.encode(interdicted_checks['clean_name'].tolist(), convert_to_tensor=True)
client_embeddings = model.encode(client_database['clean_name'].tolist(), convert_to_tensor=True)

# Compute cosine similarity
cosine_scores = util.pytorch_cos_sim(interdicted_embeddings, client_embeddings)

# Identify the most similar names
threshold = 0.8  # Similarity threshold for considering a match
matches = []
for i in range(len(interdicted_checks)):
    for j in range(len(client_database)):
        if cosine_scores[i][j] >= threshold:
            matches.append((interdicted_checks['combined_name'][i], client_database['combined_name'][j], cosine_scores[i][j].item()))

# Create a DataFrame of matches
matches_df = pd.DataFrame(matches, columns=['Interdicted Name', 'Client Name', 'Similarity'])
print(matches_df)

# Save the matches to a CSV file
matches_df.to_csv('matches.csv', index=False)
