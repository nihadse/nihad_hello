import pandas as pd

# Sample DataFrame
data = {
    'Name': ['John Doe', 'Jane Smith', 'Alice Wonderland', 'Bob Bob'],
    'rename': ['Doe', 'Smith', 'Wonderland', 'Bob']
}

df = pd.DataFrame(data)

# Function to concatenate names and identify equal cases
def concatenate_names_and_find_equal(row):
    nom = row['Name'].split()[1]  # Extract last name from 'Name' column
    prénom = row['rename']  # Get 'rename' value

    if nom == prénom:
        return nom, nom  # Return only the name if they are equal
    else:
        full_name = row['Name'] + " " + prénom
        return full_name, None

# Apply function row-wise
df[['Full Name', 'Equal Name and Family Name']] = df.apply(concatenate_names_and_find_equal, axis=1, result_type='expand')

# Print the DataFrame with results
print(df)




def concatenate_names(nom, prénom):
    if nom == prénom:
        return nom  # Keep only one if they are the same
    else:
        return nom + " " + prénom  # Concatenate nom and prénom with a space in between

# Example usage:
nom = "Doe"
prénom = "John"
result = concatenate_names(nom, prénom)
print(result)  # Outputs: "Doe John"

nom = "Jane"
prénom = "Jane"
result = concatenate_names(nom, prénom)
print(result)  # Outputs: "Jane"


import pandas as pd

# Sample dataframe
data = {
    'Similarity score': [90, 96, 85, 100, 94, 97]
}
df = pd.DataFrame(data)

# Function to apply the conditions
def categorize_score(score):
    if 0 <= score <= 95:
        return "not found"
    elif score > 95:
        return ">95"

# Create the new column based on the conditions
df['Category'] = df['Similarity score'].apply(categorize_score)

print(df)





import streamlit as st
import pandas as pd
import io

# Streamlit app
st.title("Interdits de Chéquiers")

# Upload files
uploaded_interdicted_checks = st.file_uploader("Upload Interdicted Checks CSV", type="csv")
uploaded_client_database = st.file_uploader("Upload Client Database CSV", type="csv")

# Placeholder function for finding highest similarity
def find_highest_similarity(interdicted_checks, client_database, threshold=0.8):
    # Implement your similarity logic here
    # For the example, let's just return a sample DataFrame
    data = {'Interdicted': [1, 2, 3], 'Client': [4, 5, 6], 'Similarity': [0.9, 0.85, 0.95]}
    return pd.DataFrame(data)

# Function to save results to files
def save_results_to_files(df):
    # Save to CSV
    csv_buffer = io.StringIO()
    df.to_csv(csv_buffer, index=False)
    csv_data = csv_buffer.getvalue()
    
    # Save to Excel
    excel_buffer = io.BytesIO()
    with pd.ExcelWriter(excel_buffer, engine='xlsxwriter') as writer:
        df.to_excel(writer, index=False, sheet_name='Sheet1')
    excel_data = excel_buffer.getvalue()
    
    return excel_data, csv_data

# Load data and process on button click
if uploaded_interdicted_checks is not None and uploaded_client_database is not None:
    interdicted_checks = pd.read_csv(uploaded_interdicted_checks)
    client_database = pd.read_csv(uploaded_client_database)
    
    if st.button("Results"):
        result_df = find_highest_similarity(interdicted_checks, client_database, threshold=0.8)
        
        # Display results
        st.write("Similarity Results")
        st.dataframe(result_df)
        
        # Save results to files
        excel_data, csv_data = save_results_to_files(result_df)
        
        # Download buttons
        st.download_button(
            label="Download Results as CSV",
            data=csv_data,
            file_name='results.csv',
            mime='text/csv'
        )
        
        st.download_button(
            label="Download Results as Excel",
            data=excel_data,
            file_name='results.xlsx',
            mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
        )
else:
    st.write("Please upload both CSV files.")





Bonjour Hind,Racine m'a donné vos coordonnées car Salim est en congé. Nous avons une réunion avec SG samedi, donc serait-il possible de faire une réunion demain pour obtenir votre retour sur la solution IA proposée pour le problème des contrôles interdits ?Merci et bonne journée,
[Votre Nom]


Bonjour [Nom du destinataire],J'espère que vous allez bien.Comme vous le savez, Salim est actuellement en vacances. En son absence, notre équipe a développé un modèle IA pour résoudre le problème qu'il a démontré lors des récentes réunions SG.Nous aimerions qu'une personne, de préférence son remplaçant ou un autre individu qualifié, examine notre solution finale et nous donne son avis d'ici demain.Merci de nous faire savoir qui serait la meilleure personne pour cette tâche, ou s'il y a un moment convenable pour une réunion rapide de révision.Merci pour votre attention à cette question.Cordialement,


import streamlit as st
import pandas as pd

# Upload files
uploaded_interdicted_checks = st.file_uploader("Upload Interdicted Checks CSV", type="csv")
uploaded_client_database = st.file_uploader("Upload Client Database CSV", type="csv")

# Load data
if uploaded_interdicted_checks is not None and uploaded_client_database is not None:
    interdicted_checks = pd.read_csv(uploaded_interdicted_checks)
    client_database = pd.read_csv(uploaded_client_database)
    st.write("Interdicted Checks DataFrame:")
    st.write(interdicted_checks)
    st.write("Client Database DataFrame:")
    st.write(client_database)
else:
    st.write("Please upload both CSV files.")



import streamlit as st
import pandas as pd
import numpy as np
import re
import zipfile
from sentence_transformers import SentenceTransformer, util

# Function to preprocess names
def preprocess_name(name):
    name = name.lower()  # Convert to lowercase
    name = re.sub(r"[^a-z\s]", "", name)  # Remove special characters
    name = re.sub(r"\s+", "", name).strip()  # Remove extra whitespace
    for suffix in ['sarl', 'eurl', 'spa']:
        if name.endswith(suffix):
            name = suffix.strip() + name[:-len(suffix)].strip()
    return name

# Data cleaning function
def clean_data(interdicted_checks, client_database):
    # Cleaning interdicted_checks
    interdicted_checks['date_naissance'] = pd.to_datetime(interdicted_checks['date_naissance'], errors='coerce')
    interdicted_checks['nom'] = interdicted_checks['nom'].str.upper().fillna("")
    interdicted_checks['prenom'] = interdicted_checks['prenom'].str.upper().fillna("")
    interdicted_checks['Nom_abrege'] = interdicted_checks.apply(lambda row: f"{row['nom']} {row['prenom']}".strip(), axis=1)
    interdicted_checks['Nom_abrege'] = interdicted_checks['Nom_abrege'].str.replace(r'[^A-Z\s]', '', regex=True)
    interdicted_checks['Nom_abrege'] = interdicted_checks['Nom_abrege'].str.replace(r'\s+', ' ', regex=True).str.strip()
    
    interdicted_checks['Nom_abrege'] = interdicted_checks['Nom_abrege'].str.replace(r'\b(SARL|EURL|SPA|SAR)\b', '', regex=True).str.strip()
    
    # Cleaning client_database
    client_database['Code willaya de naissance'] = client_database['Code willaya de naissance'].fillna('8').astype('Int64')
    client_database['raison sociale clean'] = client_database['raison sociale clean'].apply(preprocess_name)
    client_database['raison sociale clean'] = client_database['raison sociale clean'].str.replace(r'[^a-z\s]', '', regex=True)
    client_database['raison sociale clean'] = client_database['raison sociale clean'].str.replace(r'\s+', ' ', regex=True).str.strip()
    client_database['raison sociale clean'] = client_database['raison sociale clean'].str.replace(r'\b(sarl|eurl|spa|sar)\b', '', regex=True).str.strip()

    return interdicted_checks, client_database

# Function to find highest similarity
def find_highest_similarity(df1, df2, threshold=0.8):
    model_path = "/mnt/Sentence_model_transformer"
    model = SentenceTransformer(model_path)
    
    names1 = df1['Nom_abrege'].tolist()
    names2 = df2['raison sociale clean'].tolist()
    
    embeddings1 = model.encode(names1, convert_to_tensor=True)
    embeddings2 = model.encode(names2, convert_to_tensor=True)
    
    similarity_matrix = util.pytorch_cos_sim(embeddings1, embeddings2).cpu().numpy()
    
    best_scores = {}
    best_pairs = {}
    
    for i in range(len(names1)):
        client_name = names1[i]
        for j in range(len(names2)):
            similarity_score = similarity_matrix[i][j]
            if similarity_score > threshold and similarity_score > best_scores.get(client_name, 0):
                best_scores[client_name] = similarity_score
                best_pairs[client_name] = (df2.iloc[j], similarity_score)
    
    similar_pairs = []
    for i in range(len(df1)):
        client_name = df1.iloc[i]['Nom_abrege']
        if client_name in best_pairs:
            client_match, similarity_score = best_pairs[client_name]
            similar_pairs.append({
                "Name interdicted_checks": client_name,
                "Date de naissance interdicted_checks": df1.iloc[i]['date_naissance'],
                "Lieu de naissance interdicted_checks": df1.iloc[i]['lieu de naissance'],
                "Name client database": client_match["raison sociale clean"],
                "Id": client_match["Id"],
                "Date de naissance client_database": client_match["date_naissance"],
                "Lieu de naissance client_database": client_match["lieu de naissance"],
                "Similarity Score": similarity_score
            })
    
    result_df = pd.DataFrame(similar_pairs)
    result_df["Date de naissance Match"] = result_df["Date de naissance interdicted_checks"] == result_df["Date de naissance client_database"]
    result_df["Lieu de naissance Match"] = result_df["Lieu de naissance interdicted_checks"] == result_df["Lieu de naissance client_database"]
    
    return result_df

# Function to save results to Excel and CSV
def save_results_to_files(result_df):
    below_threshold = result_df[result_df["Similarity Score"] < 0.95]
    above_threshold = result_df[result_df["Similarity Score"] > 0.95]
    dob_equal = result_df[result_df['Date de naissance client_database'] == result_df['Date de naissance interdicted_checks']]
    
    with pd.ExcelWriter('similarity_scores_VF_alldata.xlsx') as writer:
        below_threshold.to_excel(writer, sheet_name='Below_0.95', index=False)
        above_threshold.to_excel(writer, sheet_name='Above_0.95', index=False)
        dob_equal.to_excel(writer, sheet_name='DOB_Equal', index=False)
    
    result_df.to_csv('result_df_similarity_namevf_alldata.csv', index=False)
    return 'similarity_scores_VF_alldata.xlsx', 'result_df_similarity_namevf_alldata.csv'

# Streamlit app
st.title("Similarity Check Application")

# Upload files
uploaded_interdicted_checks = st.file_uploader("Upload Interdicted Checks CSV", type=["csv"])
uploaded_client_database = st.file_uploader("Upload Client Database CSV", type=["csv"])

if uploaded_interdicted_checks and uploaded_client_database:
    # Load data
    interdicted_checks = pd.read_csv(uploaded_interdicted_checks)
    client_database = pd.read_csv(uploaded_client_database)
    
    # Clean data
    interdicted_checks, client_database = clean_data(interdicted_checks, client_database)
    
    # Find similarities
    result_df = find_highest_similarity(interdicted_checks, client_database, threshold=0.8)
    
    # Display results
    st.write("Similarity Results")
    st.dataframe(result_df)
    
    # Save results to files
    excel_file, csv_file = save_results_to_files(result_df)
    
    # Option to download results
    with open(excel_file, "rb") as file:
        st.download_button(label="Download results as Excel", data=file, file_name=excel_file, mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
    
    with open(csv_file, "rb") as file:
        st.download_button(label="Download results as CSV", data=file, file_name=csv_file, mime="text/csv")
